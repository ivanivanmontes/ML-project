{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e6c72f95-6eb7-4592-b6ce-a68b0429a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e62536-4826-4dff-a374-66930029d3b8",
   "metadata": {},
   "source": [
    "### setting a seed value for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7aac3d37-3fea-4c80-a92d-11fa434e7ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 40\n",
    "tf.random.set_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f05d9e63-9914-4b91-ad3c-5eed120ae007",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_val = pd.read_csv(\"X_val.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "y_val = pd.read_csv(\"y_val.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1bcc3310-352a-4e2d-b6ad-cd61e94c955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate the model\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred_probs = model.predict(X)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(\"int32\").flatten()\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e9d03372-a650-4a27-b434-0df0feee3954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Neural Network (2 hidden layers):\n",
      "Epoch 1/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 84.0774 - val_accuracy: 0.6266 - val_loss: 0.6739\n",
      "Epoch 2/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.5105 - loss: 0.7184 - val_accuracy: 0.6297 - val_loss: 0.6671\n",
      "Epoch 3/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.5166 - loss: 0.7119 - val_accuracy: 0.7234 - val_loss: 0.6698\n",
      "Epoch 4/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.5476 - loss: 0.7167 - val_accuracy: 0.6969 - val_loss: 0.6728\n",
      "Epoch 5/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.5550 - loss: 0.7131 - val_accuracy: 0.5578 - val_loss: 0.6765\n",
      "Epoch 6/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.5577 - loss: 0.7079 - val_accuracy: 0.5234 - val_loss: 0.6823\n",
      "Epoch 7/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.5740 - loss: 0.7092 - val_accuracy: 0.5156 - val_loss: 0.6832\n",
      "Epoch 8/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.6095 - loss: 0.7216 - val_accuracy: 0.4938 - val_loss: 0.6963\n",
      "Epoch 9/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.5992 - loss: 0.6926 - val_accuracy: 0.5047 - val_loss: 0.6881\n",
      "Epoch 10/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.6081 - loss: 0.6878 - val_accuracy: 0.5094 - val_loss: 0.6874\n",
      "Epoch 11/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.6115 - loss: 0.6795 - val_accuracy: 0.5109 - val_loss: 0.6862\n",
      "Epoch 12/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.6237 - loss: 0.6708 - val_accuracy: 0.5188 - val_loss: 0.6847\n",
      "Epoch 13/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.6332 - loss: 0.6613 - val_accuracy: 0.5234 - val_loss: 0.6819\n",
      "Epoch 14/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.6495 - loss: 0.6470 - val_accuracy: 0.5328 - val_loss: 0.6720\n",
      "Epoch 15/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.6757 - loss: 0.6281 - val_accuracy: 0.5484 - val_loss: 0.6614\n",
      "Epoch 16/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.7010 - loss: 0.6131 - val_accuracy: 0.5844 - val_loss: 0.6434\n",
      "Epoch 17/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.7288 - loss: 0.5974 - val_accuracy: 0.6328 - val_loss: 0.6198\n",
      "Epoch 18/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7516 - loss: 0.5821 - val_accuracy: 0.7375 - val_loss: 0.5938\n",
      "Epoch 19/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7737 - loss: 0.5684 - val_accuracy: 0.8125 - val_loss: 0.5673\n",
      "Epoch 20/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7759 - loss: 0.5560 - val_accuracy: 0.8562 - val_loss: 0.5413\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step\n",
      "Accuracy: 0.86\n",
      "Precision: 0.96\n",
      "Recall: 0.80\n",
      "F1-Score: 0.87\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Baseline Neural Network (2 hidden layers)\n",
    "print(\"Baseline Neural Network (2 hidden layers):\")\n",
    "baseline_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "baseline_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = baseline_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "print(\"Validation Metrics:\")\n",
    "evaluate_model(baseline_model, X_val, y_val)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7f8859ef-f2c0-41d4-a26a-ea502d3297f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deeper Neural Network (3 hidden layers):\n",
      "Epoch 1/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5487 - loss: 2.2140 - val_accuracy: 0.6453 - val_loss: 0.6371\n",
      "Epoch 2/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.6396 - loss: 0.7384 - val_accuracy: 0.7031 - val_loss: 0.5532\n",
      "Epoch 3/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.6616 - loss: 0.7059 - val_accuracy: 0.6875 - val_loss: 0.6377\n",
      "Epoch 4/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.7023 - loss: 0.7292 - val_accuracy: 0.8500 - val_loss: 0.4384\n",
      "Epoch 5/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.7872 - loss: 0.4952 - val_accuracy: 0.8344 - val_loss: 0.4459\n",
      "Epoch 6/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.8035 - loss: 0.4712 - val_accuracy: 0.8875 - val_loss: 0.3785\n",
      "Epoch 7/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.8232 - loss: 0.4236 - val_accuracy: 0.8734 - val_loss: 0.3541\n",
      "Epoch 8/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.8495 - loss: 0.3833 - val_accuracy: 0.8656 - val_loss: 0.3402\n",
      "Epoch 9/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.8681 - loss: 0.3580 - val_accuracy: 0.8656 - val_loss: 0.3288\n",
      "Epoch 10/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.8753 - loss: 0.3390 - val_accuracy: 0.8594 - val_loss: 0.3200\n",
      "Epoch 11/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.8762 - loss: 0.3235 - val_accuracy: 0.8578 - val_loss: 0.3137\n",
      "Epoch 12/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.8800 - loss: 0.3120 - val_accuracy: 0.8562 - val_loss: 0.3129\n",
      "Epoch 13/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.8839 - loss: 0.3053 - val_accuracy: 0.8453 - val_loss: 0.3216\n",
      "Epoch 14/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.8800 - loss: 0.3034 - val_accuracy: 0.8344 - val_loss: 0.3373\n",
      "Epoch 15/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.8817 - loss: 0.3034 - val_accuracy: 0.8250 - val_loss: 0.3575\n",
      "Epoch 16/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.8747 - loss: 0.3242 - val_accuracy: 0.7719 - val_loss: 0.5200\n",
      "Epoch 17/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.8474 - loss: 0.3987 - val_accuracy: 0.8578 - val_loss: 0.2994\n",
      "Epoch 18/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.8970 - loss: 0.2726 - val_accuracy: 0.7047 - val_loss: 1.1834\n",
      "Epoch 19/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.7516 - loss: 1.1584 - val_accuracy: 0.9000 - val_loss: 0.2657\n",
      "Epoch 20/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9093 - loss: 0.2552 - val_accuracy: 0.8234 - val_loss: 0.3803\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step\n",
      "Accuracy: 0.82\n",
      "Precision: 0.80\n",
      "Recall: 0.95\n",
      "F1-Score: 0.87\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Deeper Neural Network (3 hidden layers)\n",
    "print(\"\\nDeeper Neural Network (3 hidden layers):\")\n",
    "deep_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "deep_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = deep_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "print(\"Validation Metrics:\")\n",
    "evaluate_model(deep_model, X_val, y_val)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "318ce9ac-a60a-43d1-897f-b464df006855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Smaller Neural Network (1 hidden layer):\n",
      "Epoch 1/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.4999 - loss: 75.5853 - val_accuracy: 0.5188 - val_loss: 0.8298\n",
      "Epoch 2/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.5034 - loss: 0.8996 - val_accuracy: 0.6125 - val_loss: 0.6462\n",
      "Epoch 3/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6138 - loss: 0.7005 - val_accuracy: 0.6781 - val_loss: 0.5740\n",
      "Epoch 4/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6958 - loss: 0.5973 - val_accuracy: 0.7125 - val_loss: 0.5525\n",
      "Epoch 5/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.7492 - loss: 0.5388 - val_accuracy: 0.7547 - val_loss: 0.4700\n",
      "Epoch 6/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.7967 - loss: 0.4641 - val_accuracy: 0.7719 - val_loss: 0.4331\n",
      "Epoch 7/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.8258 - loss: 0.4160 - val_accuracy: 0.7797 - val_loss: 0.4149\n",
      "Epoch 8/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.8391 - loss: 0.3871 - val_accuracy: 0.7875 - val_loss: 0.4059\n",
      "Epoch 9/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.8525 - loss: 0.3677 - val_accuracy: 0.7891 - val_loss: 0.4002\n",
      "Epoch 10/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.8606 - loss: 0.3526 - val_accuracy: 0.7953 - val_loss: 0.3932\n",
      "Epoch 11/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.8643 - loss: 0.3390 - val_accuracy: 0.8078 - val_loss: 0.3825\n",
      "Epoch 12/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.8686 - loss: 0.3256 - val_accuracy: 0.8156 - val_loss: 0.3691\n",
      "Epoch 13/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.8702 - loss: 0.3124 - val_accuracy: 0.8156 - val_loss: 0.3579\n",
      "Epoch 14/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.8731 - loss: 0.3016 - val_accuracy: 0.8203 - val_loss: 0.3541\n",
      "Epoch 15/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.8749 - loss: 0.2954 - val_accuracy: 0.8172 - val_loss: 0.3634\n",
      "Epoch 16/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.8746 - loss: 0.2959 - val_accuracy: 0.8078 - val_loss: 0.4007\n",
      "Epoch 17/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.8771 - loss: 0.3071 - val_accuracy: 0.7703 - val_loss: 0.5005\n",
      "Epoch 18/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.8752 - loss: 0.3264 - val_accuracy: 0.7609 - val_loss: 0.6008\n",
      "Epoch 19/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.8574 - loss: 0.3579 - val_accuracy: 0.7656 - val_loss: 0.5494\n",
      "Epoch 20/20\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.8570 - loss: 0.3514 - val_accuracy: 0.8109 - val_loss: 0.4193\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step\n",
      "Accuracy: 0.81\n",
      "Precision: 0.79\n",
      "Recall: 0.96\n",
      "F1-Score: 0.86\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 3: Smaller Neural Network (1 hidden layer)\n",
    "print(\"\\nSmaller Neural Network (1 hidden layer):\")\n",
    "small_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "small_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = small_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "print(\"Validation Metrics:\")\n",
    "evaluate_model(small_model, X_val, y_val)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f73ef021-cb40-468e-a084-ef3cfdf983e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network with L2 Regularization (weight decay):\n",
      "L2 Regularization (λ=0.001):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step\n",
      "Accuracy: 0.83\n",
      "Precision: 0.81\n",
      "Recall: 0.94\n",
      "F1-Score: 0.87\n",
      "----------------------------------------\n",
      "L2 Regularization (λ=0.01):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step\n",
      "Accuracy: 0.90\n",
      "Precision: 0.94\n",
      "Recall: 0.90\n",
      "F1-Score: 0.92\n",
      "----------------------------------------\n",
      "L2 Regularization (λ=0.1):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step\n",
      "Accuracy: 0.79\n",
      "Precision: 0.77\n",
      "Recall: 0.95\n",
      "F1-Score: 0.85\n",
      "----------------------------------------\n",
      "L2 Regularization (λ=0.2):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step\n",
      "Accuracy: 0.69\n",
      "Precision: 0.67\n",
      "Recall: 0.97\n",
      "F1-Score: 0.80\n",
      "----------------------------------------\n",
      "L2 Regularization (λ=0.5):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step\n",
      "Accuracy: 0.63\n",
      "Precision: 0.63\n",
      "Recall: 0.99\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "L2 Regularization (λ=1.0):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step\n",
      "Accuracy: 0.65\n",
      "Precision: 0.64\n",
      "Recall: 0.98\n",
      "F1-Score: 0.78\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4: Regularization (L2 weight decay)\n",
    "print(\"\\nNeural Network with L2 Regularization (weight decay):\")\n",
    "for reg in [0.001, 0.01, 0.1, 0.2, 0.5, 1.0]:\n",
    "    print(f\"L2 Regularization (λ={reg}):\")\n",
    "    regularized_model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu', kernel_regularizer=l2(reg)),\n",
    "        Dense(16, activation='relu', kernel_regularizer=l2(reg)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    regularized_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = regularized_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "    print(\"Validation Metrics:\")\n",
    "    evaluate_model(regularized_model, X_val, y_val)\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c906b-a90e-4abf-a6fb-8270260beefc",
   "metadata": {},
   "source": [
    "### lets do a final test on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "883d7dec-7e06-4862-a5a2-c5b833cf94af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step\n",
      "Test Set Metrics for Neural Network:\n",
      "Accuracy: 0.36\n",
      "Precision: 1.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Best Neural Network Architecture\n",
    "best_nn = Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "best_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "best_nn.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)  # Don't print training output\n",
    "\n",
    "# Evaluate on Test Set\n",
    "y_test_pred_probs = best_nn.predict(X_test)\n",
    "y_test_pred = (y_test_pred_probs > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Metrics for Neural Network:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2819279d-8e63-4588-81fd-9fc61265f5ca",
   "metadata": {},
   "source": [
    "### we're getting patterns of overfitting, lets try doing k-folds as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c33e8b5e-aff4-4726-a975-8dfc901deac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== Neural Network K-Fold Cross-Validation =====\n",
      "\n",
      "Fold 1 / 5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step\n",
      "Fold 1 Results - Accuracy: 0.52, Precision: 0.51, Recall: 1.00, F1-Score: 0.68\n",
      "Fold 2 / 5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Fold 2 Results - Accuracy: 0.49, Precision: 0.00, Recall: 0.00, F1-Score: 0.00\n",
      "Fold 3 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step\n",
      "Fold 3 Results - Accuracy: 0.48, Precision: 0.48, Recall: 1.00, F1-Score: 0.65\n",
      "Fold 4 / 5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n",
      "Fold 4 Results - Accuracy: 0.47, Precision: 0.00, Recall: 0.00, F1-Score: 0.00\n",
      "Fold 5 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step\n",
      "Fold 5 Results - Accuracy: 0.47, Precision: 0.47, Recall: 0.99, F1-Score: 0.63\n",
      "\n",
      "==== Neural Network Final K-Fold Results ====\n",
      "Mean Accuracy: 0.49\n",
      "Mean Precision: 0.29\n",
      "Mean Recall: 0.60\n",
      "Mean F1-Score: 0.39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "X = pd.read_csv(\"X_train.csv\")\n",
    "y = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "\n",
    "# Number of splits for K-Fold\n",
    "k_folds = 5\n",
    "\n",
    "# Store results for each model\n",
    "nn_results = {'accuracy': [], 'precision': [], 'recall': [], 'f1_score': []}\n",
    "\n",
    "# Initialize K-Fold\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# ---- Neural Network K-Fold Cross-Validation ---- #\n",
    "print(\"\\n\\n===== Neural Network K-Fold Cross-Validation =====\\n\")\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {fold + 1} / {k_folds}\")\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Best Neural Network Architecture\n",
    "    nn_model = Sequential([\n",
    "        tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the Neural Network\n",
    "    nn_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred_probs = nn_model.predict(X_test)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(\"int32\").flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store metrics for this fold\n",
    "    nn_results['accuracy'].append(accuracy)\n",
    "    nn_results['precision'].append(precision)\n",
    "    nn_results['recall'].append(recall)\n",
    "    nn_results['f1_score'].append(f1)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Results - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n",
    "    \n",
    "\n",
    "# Print Neural Network final results\n",
    "print(\"\\n==== Neural Network Final K-Fold Results ====\")\n",
    "print(f\"Mean Accuracy: {np.mean(nn_results['accuracy']):.2f}\")\n",
    "print(f\"Mean Precision: {np.mean(nn_results['precision']):.2f}\")\n",
    "print(f\"Mean Recall: {np.mean(nn_results['recall']):.2f}\")\n",
    "print(f\"Mean F1-Score: {np.mean(nn_results['f1_score']):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "77c8b4b0-5e6c-4595-b183-e9b1307a92dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "print(pd.Series(y_train).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b69ad-9b7a-4099-9833-a449c7435d72",
   "metadata": {},
   "source": [
    "### our data seems to be unbalanced, this is why the accuracy is 62 cause the model seems to always predict 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b477c39c-bad4-4ca7-b083-08143792ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Class Weights: {0: 1.2, 1: 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4945 - loss: 85.8661 - val_accuracy: 0.0311 - val_loss: 19.0184\n",
      "Epoch 2/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5332 - loss: 33.5108 - val_accuracy: 0.0311 - val_loss: 0.7000\n",
      "Epoch 3/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5358 - loss: 13.8089 - val_accuracy: 0.9229 - val_loss: 0.6099\n",
      "Epoch 4/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5307 - loss: 6.5270 - val_accuracy: 0.0311 - val_loss: 0.7449\n",
      "Epoch 5/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5901 - loss: 3.3861 - val_accuracy: 0.0311 - val_loss: 0.7107\n",
      "Epoch 6/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5917 - loss: 2.7134 - val_accuracy: 0.0311 - val_loss: 0.7336\n",
      "Epoch 7/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6090 - loss: 1.8588 - val_accuracy: 0.0311 - val_loss: 0.7154\n",
      "Epoch 8/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6065 - loss: 1.7032 - val_accuracy: 0.0311 - val_loss: 0.7263\n",
      "Epoch 9/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.6110 - loss: 1.3365 - val_accuracy: 0.0311 - val_loss: 0.7169\n",
      "Epoch 10/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6000 - loss: 1.1551 - val_accuracy: 0.0311 - val_loss: 0.7511\n",
      "Epoch 11/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6161 - loss: 1.1428 - val_accuracy: 0.0311 - val_loss: 0.7674\n",
      "Epoch 12/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6134 - loss: 1.1469 - val_accuracy: 0.0311 - val_loss: 0.7306\n",
      "Epoch 13/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.6030 - loss: 0.9654 - val_accuracy: 0.0311 - val_loss: 0.7414\n",
      "Epoch 14/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.6200 - loss: 0.8442 - val_accuracy: 0.0311 - val_loss: 0.7424\n",
      "Epoch 15/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.6069 - loss: 0.8686 - val_accuracy: 0.0311 - val_loss: 0.7639\n",
      "Epoch 16/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.6188 - loss: 0.8265 - val_accuracy: 0.0311 - val_loss: 0.7637\n",
      "Epoch 17/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.6175 - loss: 0.8957 - val_accuracy: 0.0311 - val_loss: 0.7734\n",
      "Epoch 18/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.6181 - loss: 0.7974 - val_accuracy: 0.0311 - val_loss: 0.8250\n",
      "Epoch 19/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.6141 - loss: 0.8152 - val_accuracy: 0.0311 - val_loss: 0.7808\n",
      "Epoch 20/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.6199 - loss: 0.8010 - val_accuracy: 0.0311 - val_loss: 0.7526\n",
      "Epoch 21/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.6183 - loss: 0.8014 - val_accuracy: 0.0311 - val_loss: 0.7649\n",
      "Epoch 22/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.6201 - loss: 0.7789 - val_accuracy: 0.0311 - val_loss: 0.8028\n",
      "Epoch 23/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.6219 - loss: 0.7942 - val_accuracy: 0.0311 - val_loss: 0.8051\n",
      "Epoch 24/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6197 - loss: 0.8202 - val_accuracy: 0.0311 - val_loss: 0.7478\n",
      "Epoch 25/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.5972 - loss: 0.8320 - val_accuracy: 0.0311 - val_loss: 0.7764\n",
      "Epoch 26/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.6201 - loss: 0.8097 - val_accuracy: 0.0311 - val_loss: 0.8148\n",
      "Epoch 27/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.6209 - loss: 0.7633 - val_accuracy: 0.0311 - val_loss: 0.7838\n",
      "Epoch 28/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6210 - loss: 0.8461 - val_accuracy: 0.0311 - val_loss: 0.7751\n",
      "Epoch 29/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.6208 - loss: 0.7632 - val_accuracy: 0.0311 - val_loss: 0.7673\n",
      "Epoch 30/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.6170 - loss: 0.7524 - val_accuracy: 0.0311 - val_loss: 0.7794\n",
      "Epoch 31/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6110 - loss: 0.7619 - val_accuracy: 0.0311 - val_loss: 0.7859\n",
      "Epoch 32/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6215 - loss: 0.7491 - val_accuracy: 0.0311 - val_loss: 0.7856\n",
      "Epoch 33/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6215 - loss: 0.7479 - val_accuracy: 0.0311 - val_loss: 0.7753\n",
      "Epoch 34/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6200 - loss: 0.7877 - val_accuracy: 0.0311 - val_loss: 0.7859\n",
      "Epoch 35/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6205 - loss: 0.7511 - val_accuracy: 0.0311 - val_loss: 0.7750\n",
      "Epoch 36/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5917 - loss: 0.8008 - val_accuracy: 0.0311 - val_loss: 0.7861\n",
      "Epoch 37/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6190 - loss: 0.7789 - val_accuracy: 0.0311 - val_loss: 0.7883\n",
      "Epoch 38/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6223 - loss: 0.7569 - val_accuracy: 0.0311 - val_loss: 0.7902\n",
      "Epoch 39/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6086 - loss: 0.7473 - val_accuracy: 0.0311 - val_loss: 0.7920\n",
      "Epoch 40/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6218 - loss: 0.7809 - val_accuracy: 0.0311 - val_loss: 0.7933\n",
      "Epoch 41/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6181 - loss: 0.7464 - val_accuracy: 0.0311 - val_loss: 0.7960\n",
      "Epoch 42/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6193 - loss: 0.7542 - val_accuracy: 0.0311 - val_loss: 0.7973\n",
      "Epoch 43/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.6203 - loss: 0.7545 - val_accuracy: 0.0311 - val_loss: 0.7992\n",
      "Epoch 44/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.6203 - loss: 0.7365 - val_accuracy: 0.0311 - val_loss: 0.8014\n",
      "Epoch 45/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6214 - loss: 0.7435 - val_accuracy: 0.0311 - val_loss: 0.8028\n",
      "Epoch 46/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.6193 - loss: 0.7561 - val_accuracy: 0.0311 - val_loss: 0.8042\n",
      "Epoch 47/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.6208 - loss: 0.7582 - val_accuracy: 0.0311 - val_loss: 0.8051\n",
      "Epoch 48/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.6189 - loss: 0.7476 - val_accuracy: 0.0311 - val_loss: 0.8050\n",
      "Epoch 49/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.6174 - loss: 0.7383 - val_accuracy: 0.0311 - val_loss: 0.8069\n",
      "Epoch 50/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.6192 - loss: 0.7326 - val_accuracy: 0.0311 - val_loss: 0.8088\n",
      "Test Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# ---- Step 1: Load Data ---- #\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "\n",
    "# ---- Step 3: Class Weights (Manually Set) ---- #\n",
    "class_weight_dict = {0: 1.2, 1: 1.0}\n",
    "print(\"Manual Class Weights:\", class_weight_dict)\n",
    "\n",
    "# ---- Step 4: Neural Network Architecture ---- #\n",
    "nn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005, clipvalue=1.0)\n",
    "nn_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ---- Step 6: Train the Neural Network ---- #\n",
    "history = nn_model.fit(\n",
    "    X_resampled, \n",
    "    y_resampled, \n",
    "    epochs=50, \n",
    "    batch_size=64, \n",
    "    verbose=1, \n",
    "    validation_split=0.2, \n",
    "    class_weight=class_weight_dict,\n",
    ")\n",
    "\n",
    "# ---- Step 7: Evaluate Model on Test Data ---- #\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()\n",
    "\n",
    "loss, accuracy = nn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96249016-f3a4-458c-97f1-5f6a2614a4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd5117-ba1d-4f7e-83c5-b663393c5b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de63f0bf-ba64-4e88-a8d3-8d354650cf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185053c5-14bc-4f25-b6a3-f8c2fb987e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
