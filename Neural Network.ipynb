{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e6c72f95-6eb7-4592-b6ce-a68b0429a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e62536-4826-4dff-a374-66930029d3b8",
   "metadata": {},
   "source": [
    "### setting a seed value for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7aac3d37-3fea-4c80-a92d-11fa434e7ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 40\n",
    "tf.random.set_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f05d9e63-9914-4b91-ad3c-5eed120ae007",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_val = pd.read_csv(\"X_val.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "y_val = pd.read_csv(\"y_val.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1bcc3310-352a-4e2d-b6ad-cd61e94c955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate the model\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred_probs = model.predict(X)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(\"int32\").flatten()\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e9d03372-a650-4a27-b434-0df0feee3954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Neural Network (2 hidden layers):\n",
      "Epoch 1/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3970 - loss: 131.6413 - val_accuracy: 0.6250 - val_loss: 0.9419\n",
      "Epoch 2/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.6073 - loss: 0.7250 - val_accuracy: 0.6266 - val_loss: 0.6972\n",
      "Epoch 3/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.6311 - loss: 0.6663 - val_accuracy: 0.6266 - val_loss: 0.6996\n",
      "Epoch 4/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.6271 - loss: 0.6636 - val_accuracy: 0.6266 - val_loss: 0.7060\n",
      "Epoch 5/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.6346 - loss: 0.6614 - val_accuracy: 0.6266 - val_loss: 0.7090\n",
      "Epoch 6/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.6505 - loss: 0.6593 - val_accuracy: 0.6266 - val_loss: 0.7050\n",
      "Epoch 7/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.6550 - loss: 0.6564 - val_accuracy: 0.6297 - val_loss: 0.6973\n",
      "Epoch 8/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.6554 - loss: 0.6526 - val_accuracy: 0.6297 - val_loss: 0.6882\n",
      "Epoch 9/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.6584 - loss: 0.6606 - val_accuracy: 0.6281 - val_loss: 0.6893\n",
      "Epoch 10/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.6480 - loss: 0.6492 - val_accuracy: 0.6297 - val_loss: 0.6775\n",
      "Epoch 11/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.6343 - loss: 0.7610 - val_accuracy: 0.6328 - val_loss: 0.6674\n",
      "Epoch 12/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.6740 - loss: 0.6370 - val_accuracy: 0.6359 - val_loss: 0.6346\n",
      "Epoch 13/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.6617 - loss: 0.6320 - val_accuracy: 0.6391 - val_loss: 0.6312\n",
      "Epoch 14/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.6743 - loss: 0.6234 - val_accuracy: 0.6375 - val_loss: 0.6209\n",
      "Epoch 15/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.6807 - loss: 0.6161 - val_accuracy: 0.6438 - val_loss: 0.6089\n",
      "Epoch 16/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.6920 - loss: 0.6087 - val_accuracy: 0.6531 - val_loss: 0.5953\n",
      "Epoch 17/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.7074 - loss: 0.6018 - val_accuracy: 0.6609 - val_loss: 0.5844\n",
      "Epoch 18/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7157 - loss: 0.5948 - val_accuracy: 0.6766 - val_loss: 0.5734\n",
      "Epoch 19/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7231 - loss: 0.5872 - val_accuracy: 0.6000 - val_loss: 0.6571\n",
      "Epoch 20/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.7042 - loss: 0.5929 - val_accuracy: 0.7344 - val_loss: 0.5954\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step\n",
      "Accuracy: 0.73\n",
      "Precision: 0.96\n",
      "Recall: 0.60\n",
      "F1-Score: 0.74\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Baseline Neural Network (2 hidden layers)\n",
    "print(\"Baseline Neural Network (2 hidden layers):\")\n",
    "baseline_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "baseline_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = baseline_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "print(\"Validation Metrics:\")\n",
    "evaluate_model(baseline_model, X_val, y_val)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7f8859ef-f2c0-41d4-a26a-ea502d3297f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deeper Neural Network (3 hidden layers):\n",
      "Epoch 1/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5425 - loss: 4.8057 - val_accuracy: 0.4219 - val_loss: 0.7403\n",
      "Epoch 2/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.5680 - loss: 0.8271 - val_accuracy: 0.6578 - val_loss: 0.6584\n",
      "Epoch 3/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.6655 - loss: 0.8158 - val_accuracy: 0.6812 - val_loss: 0.5968\n",
      "Epoch 4/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.6996 - loss: 0.6417 - val_accuracy: 0.6797 - val_loss: 0.6325\n",
      "Epoch 5/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.7277 - loss: 0.6703 - val_accuracy: 0.7094 - val_loss: 0.5215\n",
      "Epoch 6/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.8240 - loss: 0.4991 - val_accuracy: 0.6625 - val_loss: 0.9828\n",
      "Epoch 7/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.6846 - loss: 0.9954 - val_accuracy: 0.6891 - val_loss: 0.6495\n",
      "Epoch 8/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.7923 - loss: 0.4916 - val_accuracy: 0.6625 - val_loss: 0.5908\n",
      "Epoch 9/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.7842 - loss: 0.4873 - val_accuracy: 0.7766 - val_loss: 0.4924\n",
      "Epoch 10/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8065 - loss: 0.4554 - val_accuracy: 0.8641 - val_loss: 0.3607\n",
      "Epoch 11/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.8681 - loss: 0.3715 - val_accuracy: 0.7437 - val_loss: 0.4859\n",
      "Epoch 12/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.8506 - loss: 0.3802 - val_accuracy: 0.7219 - val_loss: 0.5881\n",
      "Epoch 13/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.8336 - loss: 0.4056 - val_accuracy: 0.5766 - val_loss: 1.1172\n",
      "Epoch 14/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.8115 - loss: 0.4784 - val_accuracy: 0.6562 - val_loss: 0.6958\n",
      "Epoch 15/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.8378 - loss: 0.3852 - val_accuracy: 0.8813 - val_loss: 0.3096\n",
      "Epoch 16/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.8917 - loss: 0.3082 - val_accuracy: 0.7031 - val_loss: 0.6022\n",
      "Epoch 17/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.8391 - loss: 0.3766 - val_accuracy: 0.6219 - val_loss: 0.9213\n",
      "Epoch 18/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.8273 - loss: 0.4114 - val_accuracy: 0.6828 - val_loss: 0.7100\n",
      "Epoch 19/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.8400 - loss: 0.3741 - val_accuracy: 0.6578 - val_loss: 0.8209\n",
      "Epoch 20/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.8430 - loss: 0.3838 - val_accuracy: 0.6391 - val_loss: 0.9323\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step\n",
      "Accuracy: 0.64\n",
      "Precision: 0.99\n",
      "Recall: 0.42\n",
      "F1-Score: 0.59\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Deeper Neural Network (3 hidden layers)\n",
    "print(\"\\nDeeper Neural Network (3 hidden layers):\")\n",
    "deep_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "deep_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = deep_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "print(\"Validation Metrics:\")\n",
    "evaluate_model(deep_model, X_val, y_val)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "318ce9ac-a60a-43d1-897f-b464df006855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Smaller Neural Network (1 hidden layer):\n",
      "Epoch 1/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4191 - loss: 120.0025 - val_accuracy: 0.5813 - val_loss: 0.9754\n",
      "Epoch 2/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.5560 - loss: 0.8910 - val_accuracy: 0.6203 - val_loss: 1.0409\n",
      "Epoch 3/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.6143 - loss: 0.7118 - val_accuracy: 0.5422 - val_loss: 0.8383\n",
      "Epoch 4/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.6677 - loss: 0.6444 - val_accuracy: 0.6750 - val_loss: 0.5777\n",
      "Epoch 5/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7456 - loss: 0.5346 - val_accuracy: 0.6844 - val_loss: 0.6305\n",
      "Epoch 6/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.7745 - loss: 0.4905 - val_accuracy: 0.7125 - val_loss: 0.5538\n",
      "Epoch 7/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.8125 - loss: 0.4474 - val_accuracy: 0.7203 - val_loss: 0.5417\n",
      "Epoch 8/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.8214 - loss: 0.4293 - val_accuracy: 0.8641 - val_loss: 0.3658\n",
      "Epoch 9/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.8479 - loss: 0.3952 - val_accuracy: 0.6047 - val_loss: 0.8756\n",
      "Epoch 10/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.8077 - loss: 0.4553 - val_accuracy: 0.6125 - val_loss: 0.8806\n",
      "Epoch 11/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.8191 - loss: 0.4370 - val_accuracy: 0.6031 - val_loss: 0.9464\n",
      "Epoch 12/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.8280 - loss: 0.4301 - val_accuracy: 0.6094 - val_loss: 0.9455\n",
      "Epoch 13/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.8310 - loss: 0.4203 - val_accuracy: 0.6422 - val_loss: 0.8259\n",
      "Epoch 14/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.8377 - loss: 0.3969 - val_accuracy: 0.6422 - val_loss: 0.8541\n",
      "Epoch 15/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.8379 - loss: 0.3956 - val_accuracy: 0.6266 - val_loss: 0.9675\n",
      "Epoch 16/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.8390 - loss: 0.4070 - val_accuracy: 0.6266 - val_loss: 1.0015\n",
      "Epoch 17/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.8409 - loss: 0.4013 - val_accuracy: 0.6656 - val_loss: 0.8367\n",
      "Epoch 18/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.8504 - loss: 0.3627 - val_accuracy: 0.6969 - val_loss: 0.7258\n",
      "Epoch 19/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.8578 - loss: 0.3355 - val_accuracy: 0.7281 - val_loss: 0.6617\n",
      "Epoch 20/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.8694 - loss: 0.3174 - val_accuracy: 0.7516 - val_loss: 0.6226\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step\n",
      "Accuracy: 0.75\n",
      "Precision: 1.00\n",
      "Recall: 0.60\n",
      "F1-Score: 0.75\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 3: Smaller Neural Network (1 hidden layer)\n",
    "print(\"\\nSmaller Neural Network (1 hidden layer):\")\n",
    "small_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "small_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = small_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "print(\"Validation Metrics:\")\n",
    "evaluate_model(small_model, X_val, y_val)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f73ef021-cb40-468e-a084-ef3cfdf983e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network with L2 Regularization (weight decay):\n",
      "L2 Regularization (λ=0.001):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step\n",
      "Accuracy: 0.68\n",
      "Precision: 0.99\n",
      "Recall: 0.48\n",
      "F1-Score: 0.65\n",
      "----------------------------------------\n",
      "L2 Regularization (λ=0.01):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step\n",
      "Accuracy: 0.54\n",
      "Precision: 0.99\n",
      "Recall: 0.27\n",
      "F1-Score: 0.43\n",
      "----------------------------------------\n",
      "L2 Regularization (λ=0.1):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step\n",
      "Accuracy: 0.82\n",
      "Precision: 0.80\n",
      "Recall: 0.95\n",
      "F1-Score: 0.87\n",
      "----------------------------------------\n",
      "L2 Regularization (λ=0.2):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step\n",
      "Accuracy: 0.83\n",
      "Precision: 0.91\n",
      "Recall: 0.81\n",
      "F1-Score: 0.86\n",
      "----------------------------------------\n",
      "L2 Regularization (λ=0.5):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step\n",
      "Accuracy: 0.64\n",
      "Precision: 0.70\n",
      "Recall: 0.72\n",
      "F1-Score: 0.71\n",
      "----------------------------------------\n",
      "L2 Regularization (λ=1.0):\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4: Regularization (L2 weight decay)\n",
    "print(\"\\nNeural Network with L2 Regularization (weight decay):\")\n",
    "for reg in [0.001, 0.01, 0.1, 0.2, 0.5, 1.0]:\n",
    "    print(f\"L2 Regularization (λ={reg}):\")\n",
    "    regularized_model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu', kernel_regularizer=l2(reg)),\n",
    "        Dense(16, activation='relu', kernel_regularizer=l2(reg)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    regularized_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = regularized_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "    print(\"Validation Metrics:\")\n",
    "    evaluate_model(regularized_model, X_val, y_val)\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "971006f1-3a6c-4638-8fe6-72dda5fc639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network with Dropout Regularization:\n",
      "Dropout Rate: 0.1\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Dropout Rate: 0.2\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Dropout Rate: 0.3\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Dropout Rate: 0.4\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Dropout Rate: 0.5\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Dropout Rate: 0.6\n",
      "Validation Metrics:\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 5: Dropout Regularization\n",
    "print(\"\\nNeural Network with Dropout Regularization:\")\n",
    "for dropout_rate in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]:\n",
    "    print(f\"Dropout Rate: {dropout_rate}\")\n",
    "    dropout_model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    dropout_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = dropout_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "    print(\"Validation Metrics:\")\n",
    "    evaluate_model(dropout_model, X_val, y_val)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c906b-a90e-4abf-a6fb-8270260beefc",
   "metadata": {},
   "source": [
    "### lets do a final test on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "883d7dec-7e06-4862-a5a2-c5b833cf94af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test Set Metrics for Neural Network:\n",
      "Accuracy: 0.64\n",
      "Precision: 0.64\n",
      "Recall: 1.00\n",
      "F1-Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Best Neural Network Architecture\n",
    "best_nn = Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "best_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "best_nn.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)  # Don't print training output\n",
    "\n",
    "# Evaluate on Test Set\n",
    "y_test_pred_probs = best_nn.predict(X_test)\n",
    "y_test_pred = (y_test_pred_probs > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Metrics for Neural Network:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc85e0-13ea-49f2-aaaf-fcfa6e46a431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
