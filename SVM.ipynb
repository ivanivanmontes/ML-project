{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7bcb1b4a-1f22-4f34-8107-aa42cf7097d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397238ff-6cb5-4b90-afcb-fe54da26baaa",
   "metadata": {},
   "source": [
    "### Setting a seed value for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f6c6b8f-3740-4251-92b3-ec19794e9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_val = pd.read_csv(\"X_val.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "y_val = pd.read_csv(\"y_val.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65298cba-ece7-4aa7-83ac-ca84a9ace678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate the model\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "751ae178-3b7b-4c5b-be58-e2ad489b7f79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with RBF Kernel:\n",
      "Regularization C=0.01\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=0.1\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=1\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=10\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=100\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=1000\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Default RBF kernel with different regularization values\n",
    "print(\"SVM with RBF Kernel:\")\n",
    "for C in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    print(f\"Regularization C={C}\")\n",
    "    svm_rbf = SVC(kernel='rbf', C=C, gamma='scale', random_state=42)\n",
    "    svm_rbf.fit(X_train, y_train)\n",
    "    print(\"Validation Metrics:\")\n",
    "    evaluate_model(svm_rbf, X_val, y_val)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f0c71c6-ce53-461c-8ad7-da0ebe559fdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM with Polynomial Kernel (Degree 2):\n",
      "Regularization C=0.01\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=0.1\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=1\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=10\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=100\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=1000\n",
      "Validation Metrics:\n",
      "Accuracy: 0.70\n",
      "Precision: 0.68\n",
      "Recall: 0.99\n",
      "F1-Score: 0.80\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Polynomial kernel with degree 2\n",
    "print(\"\\nSVM with Polynomial Kernel (Degree 2):\")\n",
    "for C in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    print(f\"Regularization C={C}\")\n",
    "    svm_poly = SVC(kernel='poly', degree=2, C=C, gamma='scale', random_state=42)\n",
    "    svm_poly.fit(X_train, y_train)\n",
    "    print(\"Validation Metrics:\")\n",
    "    evaluate_model(svm_poly, X_val, y_val)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a12fd0c0-1f95-4866-9047-ad9b1923f0e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\nSVM with Linear Kernel:\")\\nfor C in [0.01, 0.1, 1, 10, 100, 1000]:\\n    print(f\"Regularization C={C}\")\\n    svm_linear = SVC(kernel=\\'linear\\', C=C, random_state=42)\\n    svm_linear.fit(X_train, y_train)\\n    print(\"Validation Metrics:\")\\n    evaluate_model(svm_linear, X_val, y_val)\\n    print(\"-\" * 40)\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 3: Linear kernel. Code is not executing skip this\n",
    "\"\"\"\n",
    "print(\"\\nSVM with Linear Kernel:\")\n",
    "for C in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    print(f\"Regularization C={C}\")\n",
    "    svm_linear = SVC(kernel='linear', C=C, random_state=42)\n",
    "    svm_linear.fit(X_train, y_train)\n",
    "    print(\"Validation Metrics:\")\n",
    "    evaluate_model(svm_linear, X_val, y_val)\n",
    "    print(\"-\" * 40)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce975e39-86ac-4deb-8ac3-53e25d5c969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM with RBF Kernel and PCA Transformation:\n",
      "Regularization C=0.01\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=0.1\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=1\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=10\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=100\n",
      "Validation Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1-Score: 0.77\n",
      "----------------------------------------\n",
      "Regularization C=1000\n",
      "Validation Metrics:\n",
      "Accuracy: 0.87\n",
      "Precision: 0.86\n",
      "Recall: 0.94\n",
      "F1-Score: 0.90\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4: PCA Transformation + RBF Kernel\n",
    "print(\"\\nSVM with RBF Kernel and PCA Transformation:\")\n",
    "pca = PCA(n_components=5)  # Reduce to 5 components for experimentation\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "for C in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    print(f\"Regularization C={C}\")\n",
    "    svm_rbf_pca = SVC(kernel='rbf', C=C, gamma='scale', random_state=42)\n",
    "    svm_rbf_pca.fit(X_train_pca, y_train)\n",
    "    print(\"Validation Metrics:\")\n",
    "    evaluate_model(svm_rbf_pca, X_val_pca, y_val)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642db86-4fbe-40a5-b4fc-bc6a8878d0d7",
   "metadata": {},
   "source": [
    "### Lets do a final test on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ce9a6cb-544b-441b-9a3e-2175782e5842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Metrics for SVM (RBF + PCA, C=1000):\n",
      "Accuracy: 0.64\n",
      "Precision: 0.64\n",
      "Recall: 1.00\n",
      "F1-Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# PCA Transformation\n",
    "pca = PCA(n_components=0.95)  # Use same PCA setup as before\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Best SVM Model (RBF Kernel, C=1000)\n",
    "best_svm = SVC(kernel='rbf', C=1000, random_state=42)\n",
    "best_svm.fit(X_train_pca, y_train)\n",
    "\n",
    "# Evaluate on Test Set\n",
    "y_test_pred = best_svm.predict(X_test_pca)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Metrics for SVM (RBF + PCA, C=1000):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f32be-90b9-49f0-8b54-a4d6f608e113",
   "metadata": {},
   "source": [
    "### Hmmm it seems like our accuracy went down, this might be due to overfitting??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1438956a-f782-4a91-a2a4-988804c1d690",
   "metadata": {},
   "source": [
    "### lets try the K-folds approach to see if this increases the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6863e6fe-79ca-46bc-b339-51bd56ef6ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== SVM K-Fold Cross-Validation =====\n",
      "\n",
      "Fold 1 / 5\n",
      "Fold 1 Results - Accuracy: 0.64, Precision: 0.64, Recall: 1.00, F1-Score: 0.78\n",
      "Fold 2 / 5\n",
      "Fold 2 Results - Accuracy: 0.62, Precision: 0.62, Recall: 1.00, F1-Score: 0.76\n",
      "Fold 3 / 5\n",
      "Fold 3 Results - Accuracy: 0.61, Precision: 0.61, Recall: 1.00, F1-Score: 0.76\n",
      "Fold 4 / 5\n",
      "Fold 4 Results - Accuracy: 0.63, Precision: 0.63, Recall: 1.00, F1-Score: 0.77\n",
      "Fold 5 / 5\n",
      "Fold 5 Results - Accuracy: 0.59, Precision: 0.59, Recall: 1.00, F1-Score: 0.74\n",
      "\n",
      "==== SVM Final K-Fold Results ====\n",
      "Mean Accuracy: 0.62\n",
      "Mean Precision: 0.62\n",
      "Mean Recall: 1.00\n",
      "Mean F1-Score: 0.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "X = pd.read_csv(\"X_train.csv\")\n",
    "y = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "\n",
    "# Number of splits for K-Fold\n",
    "k_folds = 5\n",
    "\n",
    "# Store results for each model\n",
    "svm_results = {'accuracy': [], 'precision': [], 'recall': [], 'f1_score': []}\n",
    "nn_results = {'accuracy': [], 'precision': [], 'recall': [], 'f1_score': []}\n",
    "\n",
    "# Initialize K-Fold\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# ---- SVM K-Fold Cross-Validation ---- #\n",
    "print(\"\\n\\n===== SVM K-Fold Cross-Validation =====\\n\")\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {fold + 1} / {k_folds}\")\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # PCA Transformation\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Best SVM Model (RBF Kernel, C=1000)\n",
    "    svm_model = SVC(kernel='rbf', C=1000, random_state=42)\n",
    "    svm_model.fit(X_train_pca, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = svm_model.predict(X_test_pca)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store metrics for this fold\n",
    "    svm_results['accuracy'].append(accuracy)\n",
    "    svm_results['precision'].append(precision)\n",
    "    svm_results['recall'].append(recall)\n",
    "    svm_results['f1_score'].append(f1)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Results - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n",
    "    \n",
    "\n",
    "# Print SVM final results\n",
    "print(\"\\n==== SVM Final K-Fold Results ====\")\n",
    "print(f\"Mean Accuracy: {np.mean(svm_results['accuracy']):.2f}\")\n",
    "print(f\"Mean Precision: {np.mean(svm_results['precision']):.2f}\")\n",
    "print(f\"Mean Recall: {np.mean(svm_results['recall']):.2f}\")\n",
    "print(f\"Mean F1-Score: {np.mean(svm_results['f1_score']):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a3aebc-4db5-4cc0-8af6-b06dfa0b184b",
   "metadata": {},
   "source": [
    "### I'm not noticing an increase in accuracy. in fact, 0.62 is intersting in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f9d5592-59db-49b4-be0e-9af3c9d0c3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    0.617805\n",
      "0.0    0.382195\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "print(pd.Series(y_train).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f4ffa-1bb5-40d8-87ae-4a103f5389cf",
   "metadata": {},
   "source": [
    "### Let's try this again!! Our data seems to be imbalanced so we're going to tell the SVM to \"care more\" about the minority class (0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7410c7e2-9b94-4135-9bbb-52f2f5c863e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== SVM K-Fold Cross-Validation =====\n",
      "\n",
      "Fold 1 / 5\n",
      "Fold 1 Results - Accuracy: 0.48, Precision: 0.64, Recall: 0.45, F1-Score: 0.53\n",
      "Fold 2 / 5\n",
      "Fold 2 Results - Accuracy: 0.50, Precision: 0.61, Recall: 0.51, F1-Score: 0.56\n",
      "Fold 3 / 5\n",
      "Fold 3 Results - Accuracy: 0.55, Precision: 0.61, Recall: 0.69, F1-Score: 0.65\n",
      "Fold 4 / 5\n",
      "Fold 4 Results - Accuracy: 0.54, Precision: 0.66, Recall: 0.56, F1-Score: 0.60\n",
      "Fold 5 / 5\n",
      "Fold 5 Results - Accuracy: 0.47, Precision: 0.57, Recall: 0.41, F1-Score: 0.48\n",
      "\n",
      "==== SVM Final K-Fold Results ====\n",
      "Mean Accuracy: 0.51\n",
      "Mean Precision: 0.62\n",
      "Mean Recall: 0.52\n",
      "Mean F1-Score: 0.56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "X = pd.read_csv(\"X_train.csv\")\n",
    "y = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "\n",
    "# Number of splits for K-Fold\n",
    "k_folds = 5\n",
    "\n",
    "# Store results for each model\n",
    "svm_results = {'accuracy': [], 'precision': [], 'recall': [], 'f1_score': []}\n",
    "\n",
    "# Initialize K-Fold\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# ---- SVM K-Fold Cross-Validation ---- #\n",
    "print(\"\\n\\n===== SVM K-Fold Cross-Validation =====\\n\")\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {fold + 1} / {k_folds}\")\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # PCA Transformation\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Best SVM Model (RBF Kernel, C=1000)\n",
    "    svm_model = SVC(kernel='rbf', C=1000, random_state=42, class_weight='balanced') # we signal that the labels may be unbalanced\n",
    "    svm_model.fit(X_train_pca, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = svm_model.predict(X_test_pca)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store metrics for this fold\n",
    "    svm_results['accuracy'].append(accuracy)\n",
    "    svm_results['precision'].append(precision)\n",
    "    svm_results['recall'].append(recall)\n",
    "    svm_results['f1_score'].append(f1)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Results - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n",
    "    \n",
    "\n",
    "# Print SVM final results\n",
    "print(\"\\n==== SVM Final K-Fold Results ====\")\n",
    "print(f\"Mean Accuracy: {np.mean(svm_results['accuracy']):.2f}\")\n",
    "print(f\"Mean Precision: {np.mean(svm_results['precision']):.2f}\")\n",
    "print(f\"Mean Recall: {np.mean(svm_results['recall']):.2f}\")\n",
    "print(f\"Mean F1-Score: {np.mean(svm_results['f1_score']):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b756f-fdf9-42b1-b7dc-e1c3604ab673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
